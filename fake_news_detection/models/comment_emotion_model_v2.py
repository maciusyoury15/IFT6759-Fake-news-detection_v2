# -*- coding: utf-8 -*-
"""comment_emotion_model_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KyKrD_vmoODcimejfGgxb_Aq0QdMV65x
"""

# Commented out IPython magic to ensure Python compatibility.
#@title Mount your Google Drive
# %matplotlib inline
# %load_ext autoreload
# %autoreload 2

from google.colab import drive
drive.mount('/content/gdrive')

from google.colab import drive
drive.flush_and_unmount()

drive.mount('/content/gdrive')

import multiprocessing
print("CPU å†…æ ¸æ•°:", multiprocessing.cpu_count())

import sys
import os
import shutil
import warnings

folder = "/content/gdrive/MyDrive/YX_homework"
!ln -Ts "$folder" /content/news_data 2> /dev/null

if '/content/news_data' not in sys.path:
  sys.path.insert(0, '/content/news_data')

# Check if CUDA is available
import torch
if not torch.cuda.is_available():
  warnings.warn('CUDA is not available.')

!ls /content/news_data/

"""## 1. Install packages and Load data"""

# Install packages
import subprocess

packages = [
    "gdown",
    "textblob",
    "NRCLex==3.0.0",
    "autocorrect==1.1.0",
    "contractions",
    "unidecode",
    "emoji",
    "nltk",
    "scikit-learn",
    "tensorflow"
]

subprocess.run("pip install --upgrade pip setuptools -q", shell=True)

for package in packages:
    try:
        print(f"Installing {package}...")
        subprocess.run(f"pip install -q {package}", shell=True, check=True)
        print(f"{package} installed successfully.")
    except subprocess.CalledProcessError as e:
        print(f"Error installing {package}: {e}")

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

import pandas as pd

# Load train, validation, and test data (TSV files)
df_train = pd.read_csv('/content/news_data/multimodal_train.tsv', sep='\t', on_bad_lines='skip')
df_val   = pd.read_csv('/content/news_data/multimodal_validate.tsv', sep='\t', on_bad_lines='skip')
df_test  = pd.read_csv('/content/news_data/multimodal_test_public.tsv', sep='\t', on_bad_lines='skip')

df_posts = pd.concat([df_train, df_val, df_test], ignore_index=True)
print("Total posts loaded:", len(df_posts))

import pandas as pd

# Load train, validation, and test data (TSV files)
# df_train = pd.read_csv('/content/news_data/multimodal_train_80k.tsv', sep='\t', on_bad_lines='skip')
# df_val   = pd.read_csv('/content/news_data/multimodal_eval_20k.tsv', sep='\t', on_bad_lines='skip')
# df_test  = pd.read_csv('/content/news_data/multimodal_test_public.tsv', sep='\t', on_bad_lines='skip')

# df_posts = pd.concat([df_train, df_val], ignore_index=True)
# print("Total posts loaded:", len(df_posts))

# Load comments data
df_comments = pd.read_csv('/content/news_data/all_comment.tsv', sep='\t', on_bad_lines='skip')
print("Total comments loaded:", len(df_comments))
# Peek at columns
# print("Post columns:", df_posts.columns.tolist())
print("Comment columns:", df_comments.columns.tolist())

df_posts['2_way_label'].mean()

"""## 2. Data pre-processing"""

# Remove posts with missing or empty titles
df_posts = df_posts.dropna(subset=['clean_title'])
print(len(df_posts))
df_posts = df_posts[df_posts['clean_title'].str.strip().astype(bool)]
print(len(df_posts))

df_posts = df_posts.dropna(subset=['2_way_label'])
print(len(df_posts))

df_posts['2_way_label'] = df_posts['2_way_label'].astype(int)
print(len(df_posts))

# post_ids_with_comments = set(df_comments['submission_id'].unique())
# df_posts = df_posts[df_posts['id'].isin(post_ids_with_comments)]
print(len(df_posts))
# Drop duplicate titles if any (to remove duplicate news)
# df_posts = df_posts.drop_duplicates(subset=['clean_title'])

print("Filtered posts count:", len(df_posts))
print("Fake news count:", sum(df_posts['2_way_label'] == 1))
print("Real news count:", sum(df_posts['2_way_label'] == 0))

"""## 3. Text pre-processing"""

# Remove HTML tags and URLs.
# Normalize accented characters (e.g., â€œcafÃ©â€ -> â€œcafeâ€).
# Expand contractions (e.g., "can't" -> "cannot").
# Convert emojis to text (e.g., ðŸ˜¢ -> ":crying_face:" -> "crying face").
# Remove special characters (keeping only letters, numbers, whitespace, and ! and ? as they may carry sentiment).
# Fix spelling of words (using autocorrect).
# Remove stopwords (common words like â€œtheâ€, â€œandâ€).
# Trim extra whitespace.

import re
import string
from autocorrect import Speller
from unidecode import unidecode
import emoji
import contractions
from nltk.corpus import stopwords
import nltk

nltk.download('stopwords')

spell = Speller(lang='en')
stop_words = set(stopwords.words('english'))

punct_to_keep = "!?";

def clean_text(text: str) -> str:
    text = text.lower()
    text = re.sub(r'<.*?>', ' ', text)
    text = re.sub(r'http\S+|www\.\S+', ' ', text)
    text = contractions.fix(text)
    text = emoji.demojize(text, delimiters=(" ", " "))
    text = unidecode(text)
    text = text.replace(":", " ")
    text = text.replace("_", " ")
    text = re.sub(f"[^{re.escape(string.ascii_letters + string.digits + string.whitespace + punct_to_keep)}]", " ", text)
    text = re.sub(r'\s+', ' ', text).strip()
    corrected_words = []
    for word in text.split():
        if word not in punct_to_keep:
            corrected = spell(word)
        else:
            corrected = word
        corrected_words.append(corrected)
    text = ' '.join(corrected_words)
    text = ' '.join(w for w in text.split() if w not in stop_words)
    text = text.strip()
    return text

# Test cases
test_cases = [
    "Great!!! This isn't a <b>drill</b> ðŸ˜±. https://example.com now.",
    "great !!! drill ðŸ˜±",
    "Happy ðŸ˜Š day",
    "Sad ðŸ˜¢ tears",
    "CafÃ© ðŸ˜ time"  # Test with accented characters
]

for test in test_cases:
    print("Original:", test)
    print("Cleaned: ", clean_text(test))
    print()

"""## 4. Sentiment Analysis of Titles"""

from textblob import TextBlob
from tqdm import tqdm

# tqdm.pandas()
# # df_posts['title_cleaned'] = df_posts['clean_title'].apply(clean_text)
# df_posts['title_cleaned'] = df_posts['clean_title'].progress_apply(clean_text)

# df_posts['sentiment_score'] = df_posts['title_cleaned'].apply(lambda txt: TextBlob(txt).sentiment.polarity)

# print(df_posts[['clean_title', 'title_cleaned', 'sentiment_score']].head(5))

# the result ranges from -1.0 (very negative) to +1.0 (very positive), with 0 being neutral.

df_posts['sentiment_score'] = df_posts['title_cleaned'].apply(lambda txt: TextBlob(txt).sentiment.polarity)

print(df_posts[['clean_title', 'title_cleaned', 'sentiment_score']].head(5))

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.hist(df_posts['sentiment_score'].dropna(), bins=50, edgecolor='black')
plt.title('Distribution of Sentiment Scores')
plt.xlabel('Sentiment Score')
plt.ylabel('Frequency')
plt.grid(True, alpha=0.3)
plt.show()

df_posts.shape

# Define the target directory
output_dir = '/content/gdrive/MyDrive/fakenews_data'

if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Created directory: {output_dir}")
else:
    print(f"Directory already exists: {output_dir}")

# Save DataFrame to TSV
output_path = os.path.join(output_dir, 'df_posts_100k.tsv')
df_posts.to_csv(output_path, sep='\t', index=False)
print(f"DataFrame saved to {output_path}")

print("File exists:", os.path.exists(output_path))

df_sample = pd.read_csv('/content/news_data/df_posts_100k.tsv', sep='\t', on_bad_lines='skip')

df_sample = df_posts.sample(n=100000, random_state=42)

df_sample

"""## 5. Emotion Analysis of Comments"""

# Novelty group: emotions of fear, disgust, and surprise (we also include anger in this group, as it was presumably intendedâ€‹).
# Expectation group: emotions of anticipation, sadness, joy, and trustâ€‹
# Neutral group: applies if the commentâ€™s emotions are balanced (i.e., the summed scores for novelty vs. expectation emotions are equal)â€‹

from nrclex import NRCLex

# Classify a single comment into Novelty / Expectation / Neutral
def classify_comment_emotion(comment_text: str) -> str:
    text = clean_text(comment_text)
    if not text:
        return "neutral"
    emotion = NRCLex(text)
    scores = emotion.raw_emotion_scores

    novelty_score = scores.get('anger', 0) + scores.get('fear', 0) + scores.get('disgust', 0) + scores.get('surprise', 0)
    expect_score = scores.get('anticipation', 0) + scores.get('sadness', 0) + scores.get('joy', 0) + scores.get('trust', 0)

    if novelty_score > expect_score:
        return "novelty"
    elif expect_score > novelty_score:
        return "expectation"
    else:
        return "neutral"

df_comments_sample = df_comments[df_comments['submission_id'].isin(df_sample['id'])].copy()
print("Sample Comments for filtered posts:", len(df_comments_sample))

df_test = df_comments_sample.sample(n=100000, random_state=42)

import re
import string
from unidecode import unidecode
import emoji
import contractions
import pandas as pd
from joblib import Parallel, delayed
import time

punct_to_keep = "!?"
html_pattern = re.compile(r'<.*?>')
url_pattern = re.compile(r'http\S+|www\.\S+')
special_char_pattern = re.compile(f"[^{re.escape(string.ascii_letters + string.digits + string.whitespace + punct_to_keep)}]")
whitespace_pattern = re.compile(r'\s+')


def clean_text_comment(text) -> str:
    if not isinstance(text, str):
        text = str(text) if text is not None else ""
    text = text.lower()
    text = html_pattern.sub(' ', text)
    text = url_pattern.sub(' ', text)
    text = contractions.fix(text)
    text = emoji.demojize(text, delimiters=(" ", " "))
    text = unidecode(text)
    text = text.replace(":", " ").replace("_", " ")
    text = special_char_pattern.sub(' ', text)
    text = whitespace_pattern.sub(' ', text).strip()
    return text

def parallel_clean(df, column_name):
    return Parallel(n_jobs=-1)(delayed(clean_text_comment)(text) for text in df[column_name])

test = "I'm from KY, and just  ðŸ˜ happy to see a nice stor"
print("Original:", test)
print("Cleaned: ", clean_text_comment(test))

start_time = time.time()

df_comments_sample['body'] = df_comments_sample['body'].astype(str).fillna('')

df_comments_sample['comment'] = parallel_clean(df_comments_sample, 'body')

end_time = time.time()
print(f"Cleaning took {end_time - start_time:.2f} seconds")

print(df_comments_sample.head())

df_comments_sample

df_comments_sample = df_comments_sample.drop(columns=['Unnamed: 0'], errors='ignore')


df_comments_sample = df_comments_sample.reset_index(drop=True)

df_comments_sample



from joblib import Parallel, delayed
from tqdm import tqdm
import time

# parallel
def parallel_classify(df, column_name):
    # process
    results = Parallel(n_jobs=-1, backend='loky')(
        delayed(classify_comment_emotion)(text) for text in tqdm(df[column_name], desc="Classifying emotions")
    )
    return results

import nltk

nltk.download('punkt_tab', quiet=True)

## Time comsuming problem, If you are good at optimizing, please optimize it.
# from nrclex import NRCLex

# # Classify a single comment into Novelty / Expectation / Neutral
# def classify_comment_emotion(comment_text: str) -> str:
#     text = clean_text(comment_text)
#     if not text:
#         return "neutral"
#     emotion = NRCLex(text)
#     scores = emotion.raw_emotion_scores

#     novelty_score = scores.get('anger', 0) + scores.get('fear', 0) + scores.get('disgust', 0) + scores.get('surprise', 0)
#     expect_score = scores.get('anticipation', 0) + scores.get('sadness', 0) + scores.get('joy', 0) + scores.get('trust', 0)

#     if novelty_score > expect_score:
#         return "novelty"
#     elif expect_score > novelty_score:
#         return "expectation"
#     else:
#         return "neutral"

# from joblib import Parallel, delayed
# from tqdm import tqdm
# import time

# # parallel
# def parallel_classify(df, column_name):
#     # process
#     results = Parallel(n_jobs=-1, backend='loky')(
#         delayed(classify_comment_emotion)(text) for text in tqdm(df[column_name], desc="Classifying emotions")
#     )
#     return results

# # over 100 hours in 4 kernel CPU
# start = time.time()
# df_comments_sample['emotion_group'] = parallel_classify(df_comments_sample, 'comment')
# print(f"Time for 100k rows: {time.time() - start:.2f} seconds")

def classify_comment_emotion(comment_text: str) -> str:
    text = clean_text_comment(comment_text)
    if not text:
        return "neutral"
    emotion = NRCLex(text)
    scores = emotion.raw_emotion_scores

    novelty_score = scores.get('anger', 0) + scores.get('fear', 0) + scores.get('disgust', 0) + scores.get('surprise', 0)
    expect_score = scores.get('anticipation', 0) + scores.get('sadness', 0) + scores.get('joy', 0) + scores.get('trust', 0)

    if novelty_score > expect_score:
        return "novelty"
    elif expect_score > novelty_score:
        return "expectation"
    else:
        return "neutral"

def parallel_classify(df, column_name):
    results = Parallel(n_jobs=8, backend='loky')(
        delayed(classify_comment_emotion)(text) for text in tqdm(df[column_name], desc="Classifying emotions")
    )
    return results

import pandas as pd
import os
import numpy as np


n_splits = 15
split_size = len(df_comments_sample) // n_splits
remainder = len(df_comments_sample) % n_splits
df_splits = []
start_idx = 0
for i in range(n_splits):
    if i < remainder:
        end_idx = start_idx + split_size + 1
    else:
        end_idx = start_idx + split_size
    df_name = f'df_comments_{i}'
    globals()[df_name] = df_comments_sample.iloc[start_idx:end_idx].copy()
    df_splits.append(globals()[df_name])
    start_idx = end_idx

output_dir = '/content/gdrive/MyDrive/YX_homework'
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Created directory: {output_dir}")
else:
    print(f"Directory already exists: {output_dir}")


for i in range(n_splits):
    output_path = os.path.join(output_dir, f'df_comments_{i}.tsv')
    globals()[f'df_comments_{i}'].to_csv(output_path, sep='\t', index=False)
    print(f"DataFrame df_comments_{i} saved to {output_path}")

import pandas as pd
import os
import time


selected_subset = 0


output_dir = '/content/gdrive/MyDrive/YX_homework'


input_path = os.path.join(output_dir, f'df_comments_{selected_subset}.tsv')
if os.path.exists(input_path):
    df_test = pd.read_csv(input_path, sep='\t')
    print(f"Loaded df_comments_{selected_subset} from {input_path}")
else:
    raise FileNotFoundError(f"File {input_path} does not exist!")

import pandas as pd
import os
import time


output_dir = '/content/gdrive/MyDrive/YX_homework'


df_list = []


start_time = time.time()


for i in range(15):
    input_path = os.path.join(output_dir, f'df_comments_{i}.tsv')
    if os.path.exists(input_path):

        df_temp = pd.read_csv(input_path, sep='\t')
        df_list.append(df_temp)
        print(f"Loaded df_comments_{i}.tsv with {len(df_temp)} rows")
    else:
        print(f"Warning: File {input_path} does not exist, skipping...")


if df_list:
    df_combined = pd.concat(df_list, ignore_index=True)


    output_path = os.path.join(output_dir, 'df_comments_sample.tsv')

    df_combined.to_csv(output_path, sep='\t', index=False)


    end_time = time.time()
    elapsed_time = end_time - start_time


    print(f"\nSuccessfully combined {len(df_list)} files")
    print(f"Total rows in combined DataFrame: {len(df_combined)}")
    print(f"Output saved to: {output_path}")
    print(f"Time taken: {elapsed_time:.2f} seconds")
    print("File exists:", os.path.exists(output_path))
else:
    print("No files were loaded, nothing to combine!")


if 'id' in df_combined.columns:
    unique_ids = df_combined['id'].nunique()
    print(f"Number of unique IDs: {unique_ids}")

df_comments_sample = df_combined



df_test

df_comments_sample

# start = time.time()
# # df_test['emotion_group'] = parallel_classify(df_test, 'comment')  # å‡è®¾ parallel_classify å·²å®šä¹‰
# df_comments_sample['emotion_group'] = parallel_classify(df_comments_sample, 'comment')
# # print(f"Time for subset {selected_subset}: {time.time() - start:.2f} seconds")


if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Created directory: {output_dir}")
else:
    print(f"Directory already exists: {output_dir}")


output_path = os.path.join(output_dir, f'df_comments_processed.tsv')
df_comments_sample.to_csv(output_path, sep='\t', index=False)
print(f"Processed DataFrame saved to {output_path}")
print("File exists:", os.path.exists(output_path))

df_comments_sample





import pandas as pd
import os


output_dir = "/content/news_data"
output_path = os.path.join(output_dir, 'df_comments_processed.tsv')


df = pd.read_csv(output_path, sep='\t')


print(f"Successfully read file from: {output_path}")
print(f"DataFrame shape: {df.shape}")
print("\nFirst few rows of the DataFrame:")
print(df.head())


print("\nFile exists:", os.path.exists(output_path))


print("\nColumn names:")
print(list(df.columns))

output_dir = "/content/news_data"
output_path = os.path.join(output_dir, 'df_posts_100k.tsv')


df_main = pd.read_csv(output_path, sep='\t')


print(f"Successfully read file from: {output_path}")
print(f"DataFrame shape: {df_main.shape}")
print("\nFirst few rows of the DataFrame:")
print(df_main.head())

df_main.head()

df.head()









# # exacute code part
# start = time.time()
# df_comments_sample['emotion_group'] = parallel_classify(df_comments_sample, 'comment')
# print(f"Time for 100k rows: {time.time() - start:.2f} seconds")


# # Define the target directory
# output_dir = '/content/gdrive/MyDrive/YX_homework'

# if not os.path.exists(output_dir):
#     os.makedirs(output_dir)
#     print(f"Created directory: {output_dir}")
# else:
#     print(f"Directory already exists: {output_dir}")

# output_path = os.path.join(output_dir, 'df_comments_sample_100k.tsv')
# df_comments_sample.to_csv(output_path, sep='\t', index=False)
# print(f"DataFrame saved to {output_path}")

# print("File exists:", os.path.exists(output_path))

# # Define the target directory
# output_dir = '/content/gdrive/MyDrive/fakenews_data'

# # Create the directory if it doesn't exist
# if not os.path.exists(output_dir):
#     os.makedirs(output_dir)
#     print(f"Created directory: {output_dir}")
# else:
#     print(f"Directory already exists: {output_dir}")

# # Save DataFrame to TSV
# output_path = os.path.join(output_dir, 'df_sample_10k.tsv')
# df_sample.to_csv(output_path, sep='\t', index=False)
# print(f"DataFrame saved to {output_path}")

# # Verify file existence
# print("File exists:", os.path.exists(output_path))

df_sample.shape

df_comments_sample

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.hist(df_comments_sample['emotion_group'].dropna(), bins=5, edgecolor='black')
plt.title('Distribution of emotion_group')
plt.xlabel('group')
plt.ylabel('Frequency')
plt.grid(True, alpha=0.3)
plt.show()

group_counts = df_comments_sample.groupby(['submission_id', 'emotion_group']).size().unstack(fill_value=0)

for grp in ["novelty", "expectation", "neutral"]:
    if grp not in group_counts.columns:
        group_counts[grp] = 0

def dominant_group_count(row):

    nov, exp, neut = row["novelty"], row["expectation"], row["neutral"]

    if nov == exp and nov >= neut:
        return "neutral"
    if neut > nov and neut > exp:
        return "neutral"
    if nov > exp and nov >= neut:
        return "novelty"
    if exp > nov and exp >= neut:
        return "expectation"
    # If all equal (rare) or empty, call it neutral
    return "neutral"

dominant_groups = group_counts.apply(dominant_group_count, axis=1)
# Map group: expectation=0, neutral=0.5, novelty=1
group_to_value = {"expectation": 0.0, "neutral": 0.5, "novelty": 1.0}
emotion_feature = dominant_groups.map(group_to_value)

df_sample['emotion_score'] = df_sample['id'].map(emotion_feature)
df_sample['emotion_score'].fillna(0.5, inplace=True)  # if any missing (no comments or tie), assign neutral 0.5
print("Sample of emotion feature values:", df_sample[['id','emotion_score']].head(5))

print(df_sample['emotion_score'].value_counts())

# Save DataFrame to TSV
output_path = os.path.join(output_dir, 'df_sample_100k.tsv')
df_sample.to_csv(output_path, sep='\t', index=False)
print(f"DataFrame saved to {output_path}")

# Verify file existence
print("File exists:", os.path.exists(output_path))

output_dir = '/content/news_data'

import pandas as pd
import os

# Define the path to the TSV file
output_path = os.path.join(output_dir, 'df_sample_100k.tsv')

# Read the TSV file back into a DataFrame
df_sample = pd.read_csv(output_path, sep='\t')

# Optional: Verify the DataFrame
print(f"DataFrame loaded from {output_path}")
print(f"Shape of loaded DataFrame: {df_sample.shape}")

df_sample.head()

"""## 6. Prepare Data for Modeling"""

from sklearn.model_selection import train_test_split

# Define features and target
X_text = df_sample['title_cleaned'].astype(str).values  # title text
X_sentiment = df_sample['sentiment_score'].values
X_emotion = df_sample['emotion_score'].values
y = df_sample['2_way_label'].values

# Split into train and test sets
X_text_train, X_text_test, X_sent_train, X_sent_test, X_emot_train, X_emot_test, y_train, y_test = train_test_split(
    X_text, X_sentiment, X_emotion, y, test_size=0.2, random_state=42, stratify=y)

print("Training samples:", len(X_text_train))
print("Testing samples:", len(X_text_test))

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_text_train)
vocab_size = len(tokenizer.word_index) + 1
print("Vocabulary size:", vocab_size)

X_seq_train = tokenizer.texts_to_sequences(X_text_train)
X_seq_test  = tokenizer.texts_to_sequences(X_text_test)

max_len = max(len(seq) for seq in X_seq_train)
X_seq_train = pad_sequences(X_seq_train, maxlen=max_len, padding='post')
X_seq_test  = pad_sequences(X_seq_test, maxlen=max_len, padding='post')
print("Max title length:", max_len)
print("Shape of padded train sequences:", X_seq_train.shape)

# !curl -I http://nlp.stanford.edu/data/glove.6B.zip

import numpy as np
# Load GloVe 100d into memory
embeddings_index = {}
with open('/content/news_data/glove.6B.100d.txt', 'r', encoding='utf8') as f:
    for line in f:
        values = line.split()
        word = values[0]
        coeffs = np.array(values[1:], dtype='float32')
        embeddings_index[word] = coeffs
print("Total GloVe vectors loaded:", len(embeddings_index))

embedding_dim = 100
embedding_matrix = np.zeros((vocab_size, embedding_dim))
for word, idx in tokenizer.word_index.items():
    if idx >= vocab_size:
        continue
    vector = embeddings_index.get(word)
    if vector is not None:
        embedding_matrix[idx] = vector

"""## 7. Build the Bi-LSTM Model"""

import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.regularizers import l2

# Model architecture
title_input = Input(shape=(max_len,), name='title_input')
embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix],
                            input_length=max_len, trainable=True)(title_input)  # Removed kernel_regularizer
x = Dropout(0.35)(embedding_layer)  # Added dropout after embedding to regularize
x = LSTM(64, return_sequences=False, kernel_regularizer=l2(0.002),
         recurrent_dropout=0.3)(x)  # Unidirectional LSTM
x = Dropout(0.3)(x)
text_repr = Dense(32, activation='relu', kernel_regularizer=l2(0.002))(x)

sent_input = Input(shape=(1,), name='sentiment_input')
sent_dense = Dense(16, activation='relu', kernel_regularizer=l2(0.002))(sent_input)
emot_input = Input(shape=(1,), name='emotion_input')
emot_dense = Dense(16, activation='relu', kernel_regularizer=l2(0.002))(emot_input)

combined = Concatenate()([text_repr, sent_dense, emot_dense])
combined = Dense(24, activation='relu', kernel_regularizer=l2(0.002))(combined)
combined = Dropout(0.3)(combined)
output = Dense(1, activation='sigmoid')(combined)

# Compile model
model = Model(inputs=[title_input, sent_input, emot_input], outputs=output)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),
              loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),
              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])
model.summary()

"""## 8. Train the Model"""

# Prepare inputs for training and testing
X_train_inputs = {
    'title_input': X_seq_train,
    'sentiment_input': X_sent_train,
    'emotion_input': X_emot_train
}
X_test_inputs = {
    'title_input': X_seq_test,
    'sentiment_input': X_sent_test,
    'emotion_input': X_emot_test
}

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_sent_train = scaler.fit_transform(X_sent_train.reshape(-1, 1))
X_sent_test = scaler.transform(X_sent_test.reshape(-1, 1))
X_emot_train = scaler.fit_transform(X_emot_train.reshape(-1, 1))
X_emot_test = scaler.transform(X_emot_test.reshape(-1, 1))

import numpy as np
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
print("Train label distribution:", np.bincount(y_train) / len(y_train))
print("Test label distribution:", np.bincount(y_test) / len(y_test))

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001)
checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')

# Training
history = model.fit(X_train_inputs, y_train,
                    validation_data=(X_test_inputs, y_test),
                    epochs=20,
                    batch_size=256,
                    callbacks=[early_stopping, reduce_lr, checkpoint])

"""## 9. Evaluate the Model"""

# Evaluate on test set
loss, accuracy, auc = model.evaluate(X_test_inputs, y_test, verbose=0)
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test AUC: {auc:.4f}")

# compute AUC
y_pred_prob = model.predict(X_test_inputs)
from sklearn.metrics import roc_auc_score, accuracy_score
auc_manual = roc_auc_score(y_test, y_pred_prob)
acc_manual = accuracy_score(y_test, (y_pred_prob >= 0.5).astype(int))
print(f"Manual Accuracy: {acc_manual:.4f}")
print(f"Manual AUC: {auc_manual:.4f}")

print("Training loss:", history.history['loss'])
print("Validation loss:", history.history['val_loss'])
print("Training accuracy:", history.history['accuracy'])
print("Validation accuracy:", history.history['val_accuracy'])
print("Training AUC:", history.history['auc'])
print("Validation AUC:", history.history['val_auc'])

import matplotlib.pyplot as plt

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['auc'], label='Training AUC')
plt.plot(history.history['val_auc'], label='Validation AUC')
plt.title('AUC Curve')
plt.xlabel('Epoch')
plt.ylabel('AUC')
plt.legend()
plt.show()

# Define the target directory
output_dir = '/content/gdrive/MyDrive/fakenews_data'

if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"Created directory: {output_dir}")
else:
    print(f"Directory already exists: {output_dir}")

output_path = os.path.join(output_dir, 'com_model_100k.h5')
model.save(output_path)

weight_path = os.path.join(output_dir, 'com1_model_100k.weights.h5')
model.save_weights(weight_path)

print(f"model saved to {output_path}")

print("File exists:", os.path.exists(output_path))

print(f"model saved to {weight_path}")

print("File exists:", os.path.exists(weight_path))

loaded_model = tf.keras.models.load_model(output_path)
loaded_model.evaluate(X_test_inputs, y_test)

import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import MinMaxScaler



model

def preprocess_inputs(df, tokenizer, scaler_sent, scaler_emot, max_len):

    X_text = df['title_cleaned'].astype(str).values
    X_sentiment = df['sentiment_score'].values
    X_emotion = df['emotion_score'].values


    X_seq = tokenizer.texts_to_sequences(X_text)
    X_seq = pad_sequences(X_seq, maxlen=max_len, padding='post')


    X_sentiment = scaler_sent.transform(X_sentiment.reshape(-1, 1))
    X_emotion = scaler_emot.transform(X_emotion.reshape(-1, 1))

    X_inputs = {
        'title_input': X_seq,
        'sentiment_input': X_sentiment,
        'emotion_input': X_emotion
    }
    return X_inputs

scaler_sent = MinMaxScaler().fit(X_sentiment.reshape(-1, 1))
scaler_emot = MinMaxScaler().fit(X_emotion.reshape(-1, 1))
max_len = max(len(seq) for seq in tokenizer.texts_to_sequences(df_sample['title_cleaned'].astype(str)))


X_inputs = preprocess_inputs(df_sample, tokenizer, scaler_sent, scaler_emot, max_len)


probit = model.predict(X_inputs)
predictions = (probit >= 0.5).astype(int)


df_sample['probit'] = probit.flatten()
df_sample['predicted_label'] = predictions.flatten()


if '2_way_label' in df_sample.columns:
    from sklearn.metrics import accuracy_score
    accuracy = accuracy_score(df_sample['2_way_label'], df_sample['predicted_label'])
    print(f"Overall accuracy: {accuracy:.4f}")

df_sample.head()

print(df_sample[['title_cleaned', 'sentiment_score', 'emotion_score', 'probit', 'predicted_label']].head())

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt


required_columns = ['2_way_label', 'probit', 'predicted_label']
if not all(col in df_sample.columns for col in required_columns):
    raise ValueError("df_sample is missing one or more required columns: '2_way_label', 'probit', 'predicted_label'")

y_true = df_sample['2_way_label'].values
y_pred = df_sample['predicted_label'].values
y_prob = df_sample['probit'].values


accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)


roc_auc = roc_auc_score(y_true, y_prob)


print("Classification Metrics:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"ROC-AUC: {roc_auc:.4f}")


fpr, tpr, thresholds = roc_curve(y_true, y_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

df_sample.to_csv('/content/gdrive/MyDrive/fakenews_data/output_comments_model.csv', index=False)
print("Predictions saved to 'df_sample_with_predictions.csv'")

import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import os


output_file = '/content/gdrive/MyDrive/fakenews_data/output_comments_model.csv'
output_dir = '/content/gdrive/MyDrive/fakenews_data'


if os.path.exists(output_file):
    df_loaded = pd.read_csv(output_file)
    print(f"Successfully loaded file: {output_file}")
    print(f"Number of rows: {len(df_loaded)}")
else:
    raise FileNotFoundError(f"File not found at {output_file}")


print("\n=== Data Validation ===")

required_columns = ['2_way_label', 'probit', 'predicted_label']
missing_columns = [col for col in required_columns if col not in df_loaded.columns]
if missing_columns:
    print(f"Warning: Missing columns: {missing_columns}")
else:
    print("All required columns present:", required_columns)


probit_min, probit_max = df_loaded['probit'].min(), df_loaded['probit'].max()
print(f"Probit range: [{probit_min:.4f}, {probit_max:.4f}]")
if not (0 <= probit_min <= probit_max <= 1):
    print("Warning: Probit values are outside [0, 1] range!")


unique_labels = df_loaded['predicted_label'].unique()
print(f"Predicted labels: {unique_labels}")
if not set(unique_labels).issubset({0, 1}):
    print("Warning: Predicted labels contain values other than 0 or 1!")


print("\nClass distribution of true labels:")
print(df_loaded['2_way_label'].value_counts(normalize=True))

if 'df_sample' in globals():
    print("\nComparing with original df_sample:")
    print(f"Original row count: {len(df_sample)}")
    print(f"Loaded row count: {len(df_loaded)}")
    if len(df_sample) == len(df_loaded):
        print("Row counts match!")

        for col in required_columns:
            if (df_sample[col] == df_loaded[col]).all():
                print(f"Column '{col}' matches perfectly")
            else:
                print(f"Warning: Column '{col}' has differences")
    else:
        print("Warning: Row counts do not match!")


print("\n=== Classification Metrics ===")
y_true = df_loaded['2_way_label'].values
y_pred = df_loaded['predicted_label'].values
y_prob = df_loaded['probit'].values


accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, zero_division=0)
recall = recall_score(y_true, y_pred, zero_division=0)
f1 = f1_score(y_true, y_pred, zero_division=0)
roc_auc = roc_auc_score(y_true, y_prob)


print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"ROC-AUC: {roc_auc:.4f}")


fpr, tpr, thresholds = roc_curve(y_true, y_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve (Loaded Data)')
plt.legend(loc='lower right')
plt.grid(True)

df_loaded
